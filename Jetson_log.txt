 => CACHED [21/26] RUN export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/  0.0s
 => CACHED [22/26] RUN echo "export PATH=/usr/local/cuda/bin:/usr/local/c  0.0s
 => CACHED [23/26] RUN export CUDA_NVCC_EXECUTABLE=$(which nvcc)           0.0s
 => [24/26] RUN sh -c "nvcc --version;" && python3 -c "import torch;prin  20.8s
 => => # Build cuda_11.4.r11.4/compiler.31964100_0                             
 => => # TORCHVERSION:2.0.0a0+ec3941ad.nv23.02                                 
 => => # False        


user@stereo:~/workspace/DSGN2_fork/docker$ sudo sh scripts/build.sh 
[sudo] password for user: 
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
WARNING: Found orphan containers (tis_driver, ros2_driver) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up.
Building jetson-app
[+] Building 557.4s (27/28)                                                                                                           
 => [internal] load build definition from Dockerfile.aarch64                                                                     0.0s
 => => transferring dockerfile: 3.07kB                                                                                           0.0s
 => [internal] load .dockerignore                                                                                                0.0s
 => => transferring context: 2B                                                                                                  0.0s
 => [internal] load metadata for nvcr.io/nvidia/l4t-pytorch:r35.2.1-pth2.0-py3                                                   0.0s
 => [ 1/25] FROM nvcr.io/nvidia/l4t-pytorch:r35.2.1-pth2.0-py3                                                                   0.0s
 => CACHED [ 2/25] RUN useradd -m dsgn2 --uid=1001 && echo "dsgn2:user" | chpasswd                                               0.0s
 => CACHED [ 3/25] RUN apt-get update && apt-get install -y         wget vim usbutils         &&  apt install -y protobuf-compi  0.0s
 => CACHED [ 4/25] WORKDIR /home/dsgn2                                                                                           0.0s
 => CACHED [ 5/25] RUN cd /home/dsgn2 && chown -R 1001:1001 ./                                                                   0.0s
 => CACHED [ 6/25] RUN pip3 install -U --no-cache-dir protobuf3                                                                  0.0s
 => CACHED [ 7/25] RUN pip3 install -U --no-cache-dir numpy && pip3 install -U --no-cache-dir matplotlib                         0.0s
 => CACHED [ 8/25] RUN pip3 install -U --no-cache-dir pycocotools && pip3 install -U openmim                                     0.0s
 => CACHED [ 9/25] RUN mim install mmcv-full                                                                                     0.0s
 => [10/25] RUN export OPENBLAS_CORETYPE=ARMV8                                                                                   0.5s
 => [11/25] RUN git clone https://github.com/Arcwy0/DSGN2_fork --branch main                                                    27.4s
 => [12/25] RUN cd DSGN2_fork/mmdetection-v2.22.0/ && pip3 install -e .                                                         20.2s
 => [13/25] RUN apt-get update && apt update && apt install libboost-dev -y         && rm -rf /var/lib/apt/lists/*              24.9s 
 => [14/25] RUN git clone https://github.com/Arcwy0/spconv121_torch200.git                                                       1.8s 
 => [15/25] RUN cd ./spconv121_torch200/third_party/ && git clone --recurse-submodules https://github.com/pybind/pybind11.git    5.5s 
 => [16/25] RUN cd ./spconv121_torch200 && python3 setup.py bdist_wheel                                                        179.9s 
 => [17/25] RUN cd ./spconv121_torch200/dist && ls && pip3 install spconv-1.2.1-cp38-cp38-linux_aarch64.whl                      4.8s 
 => [18/25] RUN cd /home/dsgn2                                                                                                   0.7s 
 => [19/25] RUN export PATH=/usr/local/cuda/bin:/usr/local/cuda/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbi  0.8s 
 => [20/25] RUN export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:                        0.8s 
 => [21/25] RUN echo "export PATH=/usr/local/cuda/bin:/usr/local/cuda/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/u  0.8s 
 => [22/25] RUN export CUDA_NVCC_EXECUTABLE=$(which nvcc)                                                                        0.8s 
 => [23/25] RUN python3 -c "import torch;print(torch.cuda.is_available());"  && pip3 install -U Cython                          17.6s
 => ERROR [24/25] RUN cd /home/dsgn2/DSGN2_fork/ && pip3 install -r requirements.txt && pip3 install -e .                      270.6s
------                                                                                                                                
 > [24/25] RUN cd /home/dsgn2/DSGN2_fork/ && pip3 install -r requirements.txt && pip3 install -e .:                                   
#0 4.009 Collecting scikit-image                                                                                                      
#0 4.241   Downloading scikit_image-0.21.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (13.3 MB)                       
#0 7.031 Collecting fire                                                                                                              
#0 7.083   Downloading fire-0.5.0.tar.gz (88 kB)                                                                                      
#0 8.139 Collecting tensorboardX
#0 8.190   Downloading tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)
#0 8.702 Collecting tqdm
#0 8.751   Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)
#0 8.882 Requirement already satisfied: numpy in /home/dsgn2/.local/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.24.4)
#0 9.644 Collecting numba
#0 9.697   Downloading numba-0.57.1-cp38-cp38-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (3.3 MB)
#0 10.84 Collecting easydict
#0 10.89   Downloading easydict-1.10.tar.gz (6.4 kB)
#0 11.68 Requirement already satisfied: pyyaml in /home/dsgn2/.local/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (6.0)
#0 12.48 Collecting opencv-python
#0 12.54   Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (40.4 MB)
#0 18.76 Collecting PyWavelets>=1.1.1
#0 18.82   Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (6.9 MB)
#0 19.94 Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 1)) (23.0)
#0 19.95 Requirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.8/dist-packages/Pillow-9.4.0-py3.8-linux-aarch64.egg (from scikit-image->-r requirements.txt (line 1)) (9.4.0)
#0 20.24 Collecting tifffile>=2022.8.12
#0 20.29   Downloading tifffile-2023.4.12-py3-none-any.whl (219 kB)
#0 20.54 Collecting lazy_loader>=0.2
#0 20.60   Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)
#0 20.88 Collecting imageio>=2.27
#0 20.94   Downloading imageio-2.31.1-py3-none-any.whl (313 kB)
#0 21.93 Collecting scipy>=1.8
#0 21.98   Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (31.0 MB)
#0 27.21 Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 1)) (3.0)
#0 27.25 Requirement already satisfied: six in /usr/lib/python3/dist-packages (from fire->-r requirements.txt (line 2)) (1.14.0)
#0 27.39 Collecting termcolor
#0 27.45   Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)
#0 28.65 Collecting protobuf>=4.22.3
#0 28.71   Downloading protobuf-4.23.3-cp37-abi3-manylinux2014_aarch64.whl (303 kB)
#0 29.29 Collecting llvmlite<0.41,>=0.40.0dev0
#0 29.34   Downloading llvmlite-0.40.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (41.1 MB)
#0 35.54 Requirement already satisfied: importlib-metadata; python_version < "3.9" in /home/dsgn2/.local/lib/python3.8/site-packages (from numba->-r requirements.txt (line 6)) (6.7.0)
#0 35.59 Requirement already satisfied: zipp>=0.5 in /home/dsgn2/.local/lib/python3.8/site-packages (from importlib-metadata; python_version < "3.9"->numba->-r requirements.txt (line 6)) (3.15.0)
#0 35.63 Building wheels for collected packages: fire, easydict
#0 35.64   Building wheel for fire (setup.py): started
#0 36.72   Building wheel for fire (setup.py): finished with status 'done'
#0 36.73   Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116936 sha256=3297c8bb199dee9b0c0590db834bc953397680cf4afb2abf1fe38dddbdf97145
#0 36.73   Stored in directory: /home/dsgn2/.cache/pip/wheels/5b/eb/43/7295e71293b218ddfd627f935229bf54af9018add7fbb5aac6
#0 36.74   Building wheel for easydict (setup.py): started
#0 37.71   Building wheel for easydict (setup.py): finished with status 'done'
#0 37.72   Created wheel for easydict: filename=easydict-1.10-py3-none-any.whl size=6496 sha256=c86bd3c269fc63df23bd159fdfe0747488d397256e34e4a2a055537aac54aee1
#0 37.72   Stored in directory: /home/dsgn2/.cache/pip/wheels/fe/4e/02/c9c3154e4845bfdbf1fdf344f5a89f16dcbb4f627a908c9974
#0 37.72 Successfully built fire easydict
#0 39.04 Installing collected packages: PyWavelets, tifffile, lazy-loader, imageio, scipy, scikit-image, termcolor, fire, protobuf, tensorboardX, tqdm, llvmlite, numba, easydict, opencv-python
#0 64.68 Successfully installed PyWavelets-1.4.1 easydict-1.10 fire-0.5.0 imageio-2.31.1 lazy-loader-0.2 llvmlite-0.40.1 numba-0.57.1 opencv-python-4.7.0.72 protobuf-4.23.3 scikit-image-0.21.0 scipy-1.10.1 tensorboardX-2.6.1 termcolor-2.3.0 tifffile-2023.4.12 tqdm-4.65.0
#0 68.38 Obtaining file:///home/dsgn2/DSGN2_fork
#0 76.40 Requirement already satisfied: easydict in /home/dsgn2/.local/lib/python3.8/site-packages (from pcdet==0.1.0+8ee24a8) (1.10)
#0 76.41 Requirement already satisfied: numba in /home/dsgn2/.local/lib/python3.8/site-packages (from pcdet==0.1.0+8ee24a8) (0.57.1)
#0 76.43 Requirement already satisfied: numpy in /home/dsgn2/.local/lib/python3.8/site-packages (from pcdet==0.1.0+8ee24a8) (1.24.4)
#0 76.43 Requirement already satisfied: pyyaml in /home/dsgn2/.local/lib/python3.8/site-packages (from pcdet==0.1.0+8ee24a8) (6.0)
#0 76.44 Requirement already satisfied: spconv in /home/dsgn2/.local/lib/python3.8/site-packages (from pcdet==0.1.0+8ee24a8) (1.2.1)
#0 76.44 Requirement already satisfied: tensorboardX in /home/dsgn2/.local/lib/python3.8/site-packages (from pcdet==0.1.0+8ee24a8) (2.6.1)
#0 76.45 Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.8/dist-packages (from pcdet==0.1.0+8ee24a8) (2.0.0a0+ec3941ad.nv23.2)
#0 76.47 Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /home/dsgn2/.local/lib/python3.8/site-packages (from numba->pcdet==0.1.0+8ee24a8) (0.40.1)
#0 76.47 Requirement already satisfied: importlib-metadata; python_version < "3.9" in /home/dsgn2/.local/lib/python3.8/site-packages (from numba->pcdet==0.1.0+8ee24a8) (6.7.0)
#0 76.57 Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX->pcdet==0.1.0+8ee24a8) (23.0)
#0 76.58 Requirement already satisfied: protobuf>=4.22.3 in /home/dsgn2/.local/lib/python3.8/site-packages (from tensorboardX->pcdet==0.1.0+8ee24a8) (4.23.3)
#0 76.58 Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.1->pcdet==0.1.0+8ee24a8) (4.4.0)
#0 76.59 Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.1->pcdet==0.1.0+8ee24a8) (1.11.1)
#0 76.59 Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.1->pcdet==0.1.0+8ee24a8) (3.0)
#0 76.65 Requirement already satisfied: zipp>=0.5 in /home/dsgn2/.local/lib/python3.8/site-packages (from importlib-metadata; python_version < "3.9"->numba->pcdet==0.1.0+8ee24a8) (3.15.0)
#0 76.69 Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.1->pcdet==0.1.0+8ee24a8) (1.2.1)
#0 77.79 Installing collected packages: pcdet
#0 77.79   Running setup.py develop for pcdet
#0 270.3     ERROR: Command errored out with exit status 1:
#0 270.3      command: /usr/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '"'"'/home/dsgn2/DSGN2_fork/setup.py'"'"'; __file__='"'"'/home/dsgn2/DSGN2_fork/setup.py'"'"';f=getattr(tokenize, '"'"'open'"'"', open)(__file__);code=f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' develop --no-deps --user --prefix=
#0 270.3          cwd: /home/dsgn2/DSGN2_fork/
#0 270.3     Complete output (1777 lines):
#0 270.3     running develop
#0 270.3     running egg_info
#0 270.3     writing pcdet.egg-info/PKG-INFO
#0 270.3     writing dependency_links to pcdet.egg-info/dependency_links.txt
#0 270.3     writing requirements to pcdet.egg-info/requires.txt
#0 270.3     writing top-level names to pcdet.egg-info/top_level.txt
#0 270.3     reading manifest file 'pcdet.egg-info/SOURCES.txt'
#0 270.3     writing manifest file 'pcdet.egg-info/SOURCES.txt'
#0 270.3     running build_ext
#0 270.3     building 'pcdet.ops.iou3d_nms.iou3d_nms_cuda' extension
#0 270.3     creating /home/dsgn2/DSGN2_fork/build
#0 270.3     creating /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8
#0 270.3     creating /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet
#0 270.3     creating /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops
#0 270.3     creating /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms
#0 270.3     creating /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src
#0 270.3     No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
#0 270.3     Emitting ninja build file /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/build.ninja...
#0 270.3     Compiling objects...
#0 270.3     Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
#0 270.3     [1/4] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c -c /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms_kernel.cu -o /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src/iou3d_nms_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1013"' -DTORCH_EXTENSION_NAME=iou3d_nms_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -gencode=arch=compute_61,code=compute_61 -gencode=arch=compute_61,code=sm_61 -std=c++14
#0 270.3     [2/4] c++ -MMD -MF /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src/iou3d_nms_api.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c -c /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms_api.cpp -o /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src/iou3d_nms_api.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1013"' -DTORCH_EXTENSION_NAME=iou3d_nms_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14
#0 270.3     [3/4] c++ -MMD -MF /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src/iou3d_nms.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c -c /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp -o /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src/iou3d_nms.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1013"' -DTORCH_EXTENSION_NAME=iou3d_nms_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp: In function ??int boxes_overlap_bev_gpu(at::Tensor, at::Tensor, at::Tensor)??:
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:56:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3        56 |     CHECK_INPUT(boxes_a);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:57:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3        57 |     CHECK_INPUT(boxes_b);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:58:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3        58 |     CHECK_INPUT(ans_overlap);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:63:54: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3        63 |     const float * boxes_a_data = boxes_a.data<float>();
#0 270.3           |                                                      ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:64:54: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3        64 |     const float * boxes_b_data = boxes_b.data<float>();
#0 270.3           |                                                      ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:65:56: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3        65 |     float * ans_overlap_data = ans_overlap.data<float>();
#0 270.3           |                                                        ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp: In function ??int boxes_overlap_bev_onebyone_gpu(at::Tensor, at::Tensor, at::Tensor)??:
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:77:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3        77 |     CHECK_INPUT(boxes_a);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:78:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3        78 |     CHECK_INPUT(boxes_b);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:79:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3        79 |     CHECK_INPUT(ans_overlap);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:83:54: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3        83 |     const float * boxes_a_data = boxes_a.data<float>();
#0 270.3           |                                                      ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:84:54: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3        84 |     const float * boxes_b_data = boxes_b.data<float>();
#0 270.3           |                                                      ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:85:56: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3        85 |     float * ans_overlap_data = ans_overlap.data<float>();
#0 270.3           |                                                        ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp: In function ??int boxes_iou_bev_gpu(at::Tensor, at::Tensor, at::Tensor)??:
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:96:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3        96 |     CHECK_INPUT(boxes_a);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:97:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3        97 |     CHECK_INPUT(boxes_b);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:98:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3        98 |     CHECK_INPUT(ans_iou);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:103:54: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       103 |     const float * boxes_a_data = boxes_a.data<float>();
#0 270.3           |                                                      ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:104:54: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       104 |     const float * boxes_b_data = boxes_b.data<float>();
#0 270.3           |                                                      ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:105:48: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       105 |     float * ans_iou_data = ans_iou.data<float>();
#0 270.3           |                                                ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp: In function ??int boxes_iou_bev_onebyone_gpu(at::Tensor, at::Tensor, at::Tensor)??:
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:116:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3       116 |     CHECK_INPUT(boxes_a);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:117:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3       117 |     CHECK_INPUT(boxes_b);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:118:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3       118 |     CHECK_INPUT(ans_iou);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:122:54: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       122 |     const float * boxes_a_data = boxes_a.data<float>();
#0 270.3           |                                                      ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:123:54: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       123 |     const float * boxes_b_data = boxes_b.data<float>();
#0 270.3           |                                                      ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:124:48: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       124 |     float * ans_iou_data = ans_iou.data<float>();
#0 270.3           |                                                ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp: In function ??int nms_gpu(at::Tensor, at::Tensor, float)??:
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:134:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3       134 |     CHECK_INPUT(boxes);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:138:50: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       138 |     const float * boxes_data = boxes.data<float>();
#0 270.3           |                                                  ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:139:40: warning: ??T* at::Tensor::data() const [with T = long int]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       139 |     long * keep_data = keep.data<long>();
#0 270.3           |                                        ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp: In function ??int nms_normal_gpu(at::Tensor, at::Tensor, float)??:
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:15:15: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        15 |   if (!x.type().is_cuda()) { \
#0 270.3           |               ^
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:26:24: note: in expansion of macro ??CHECK_CUDA??
#0 270.3        26 | #define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
#0 270.3           |                        ^~~~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:184:5: note: in expansion of macro ??CHECK_INPUT??
#0 270.3       184 |     CHECK_INPUT(boxes);
#0 270.3           |     ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:188:50: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       188 |     const float * boxes_data = boxes.data<float>();
#0 270.3           |                                                  ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:189:40: warning: ??T* at::Tensor::data() const [with T = long int]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       189 |     long * keep_data = keep.data<long>();
#0 270.3           |                                        ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_nms.cpp:7:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     [4/4] c++ -MMD -MF /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src/iou3d_cpu.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c -c /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp -o /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src/iou3d_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1013"' -DTORCH_EXTENSION_NAME=iou3d_nms_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp: In function ??int boxes_iou_bev_cpu(at::Tensor, at::Tensor, at::Tensor)??:
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp:242:55: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       242 |     const float *boxes_a = boxes_a_tensor.data<float>();
#0 270.3           |                                                       ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp:9:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp:243:55: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       243 |     const float *boxes_b = boxes_b_tensor.data<float>();
#0 270.3           |                                                       ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp:9:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp:244:49: warning: ??T* at::Tensor::data() const [with T = float]?? is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
#0 270.3       244 |     float *ans_iou = ans_iou_tensor.data<float>();
#0 270.3           |                                                 ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/tensor.h:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp:9:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here
#0 270.3       238 |   T * data() const {
#0 270.3           |       ^~~~
#0 270.3     creating build/lib.linux-aarch64-3.8
#0 270.3     creating build/lib.linux-aarch64-3.8/pcdet
#0 270.3     creating build/lib.linux-aarch64-3.8/pcdet/ops
#0 270.3     creating build/lib.linux-aarch64-3.8/pcdet/ops/iou3d_nms
#0 270.3     aarch64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src/iou3d_cpu.o /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src/iou3d_nms_api.o /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src/iou3d_nms.o /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/iou3d_nms/src/iou3d_nms_kernel.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-aarch64-3.8/pcdet/ops/iou3d_nms/iou3d_nms_cuda.cpython-38-aarch64-linux-gnu.so
#0 270.3     building 'pcdet.ops.build_cost_volume.build_cost_volume_cuda' extension
#0 270.3     creating /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/build_cost_volume
#0 270.3     creating /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/build_cost_volume/src
#0 270.3     Emitting ninja build file /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/build.ninja...
#0 270.3     Compiling objects...
#0 270.3     Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
#0 270.3     [1/2] c++ -MMD -MF /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/build_cost_volume/src/BuildCostVolume.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c -c /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp -o /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/build_cost_volume/src/BuildCostVolume.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1013"' -DTORCH_EXTENSION_NAME=build_cost_volume_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14
#0 270.3     FAILED: /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/build_cost_volume/src/BuildCostVolume.o
#0 270.3     c++ -MMD -MF /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/build_cost_volume/src/BuildCostVolume.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c -c /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp -o /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/build_cost_volume/src/BuildCostVolume.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1013"' -DTORCH_EXTENSION_NAME=build_cost_volume_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:7,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:6:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??c10::Half AtomicFPOp<c10::Half>::operator()(c10::Half*, c10::Half, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:31:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3        31 |       old = atomicCAS(address_as_ui, assumed, old);
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:31:13: note: (if you use ??-fpermissive??, G++ will accept your code, but allowing the use of an undeclared name is deprecated)
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??c10::BFloat16 AtomicFPOp<c10::BFloat16>::operator()(c10::BFloat16*, c10::BFloat16, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:53:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3        53 |       old = atomicCAS(address_as_ui, assumed, old);
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??double AtomicFPOp<double>::operator()(double*, double, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:74:12: error: there are no arguments to ??__longlong_as_double?? that depend on a template parameter, so a declaration of ??__longlong_as_double?? must be available [-fpermissive]
#0 270.3        74 |     return __longlong_as_double(old);
#0 270.3           |            ^~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicAddIntegerImpl<T, 1>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicAddIntegerImpl<T, 2>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicAddIntegerImpl<T, 4>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:138:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       138 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:138:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       138 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicAddIntegerImpl<T, 8>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In function ??int32_t gpuAtomicAdd(int32_t*, int32_t)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:199:10: error: ??atomicAdd?? was not declared in this scope; did you mean ??gpuAtomicAdd???
#0 270.3       199 |   return atomicAdd(address, val);
#0 270.3           |          ^~~~~~~~~
#0 270.3           |          gpuAtomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In function ??c10::Half gpuAtomicAdd(c10::Half*, c10::Half)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:221:10: error: ??atomicAdd?? was not declared in this scope; did you mean ??gpuAtomicAdd???
#0 270.3       221 |   return atomicAdd(reinterpret_cast<__half*>(address), val);
#0 270.3           |          ^~~~~~~~~
#0 270.3           |          gpuAtomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In function ??c10::BFloat16 gpuAtomicAdd(c10::BFloat16*, c10::BFloat16)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:232:75: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]
#0 270.3       232 |   __nv_bfloat16 r = atomicAdd(reinterpret_cast<__nv_bfloat16*>(address), *reinterpret_cast<__nv_bfloat16*>(&val));
#0 270.3           |                                                                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:232:21: error: ??atomicAdd?? was not declared in this scope; did you mean ??gpuAtomicAdd???
#0 270.3       232 |   __nv_bfloat16 r = atomicAdd(reinterpret_cast<__nv_bfloat16*>(address), *reinterpret_cast<__nv_bfloat16*>(&val));
#0 270.3           |                     ^~~~~~~~~
#0 270.3           |                     gpuAtomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:233:11: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]
#0 270.3       233 |   return *reinterpret_cast<c10::BFloat16*>(&r);
#0 270.3           |           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:233:11: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In function ??double gpuAtomicAdd(double*, double)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:272:10: error: ??atomicAdd?? was not declared in this scope; did you mean ??gpuAtomicAdd???
#0 270.3       272 |   return atomicAdd(address, val);
#0 270.3           |          ^~~~~~~~~
#0 270.3           |          gpuAtomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In function ??float gpuAtomicAdd(float*, float)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:276:10: error: ??atomicAdd?? was not declared in this scope; did you mean ??gpuAtomicAdd???
#0 270.3       276 |   return atomicAdd(address, val);
#0 270.3           |          ^~~~~~~~~
#0 270.3           |          gpuAtomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMulIntegerImpl<T, 1>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMulIntegerImpl<T, 2>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMulIntegerImpl<T, 4>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:138:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       138 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:138:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       138 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMulIntegerImpl<T, 8>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In lambda function:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:371:67: error: ??__longlong_as_double?? was not declared in this scope
#0 270.3       371 |                                 return __double_as_longlong(val * __longlong_as_double(assumed));
#0 270.3           |                                                                   ^~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:371:40: error: ??__double_as_longlong?? was not declared in this scope
#0 270.3       371 |                                 return __double_as_longlong(val * __longlong_as_double(assumed));
#0 270.3           |                                        ^~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In function ??float gpuAtomicMul(float*, float)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:385:36: error: ??__int_as_float?? was not declared in this scope
#0 270.3       385 |                                    __int_as_float(assumed)));
#0 270.3           |                                    ^~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:384:21: error: ??__float_as_int?? was not declared in this scope
#0 270.3       384 |                     __float_as_int(val *
#0 270.3           |                     ^~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:383:11: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       383 |     old = atomicCAS(address_as_ull, assumed,
#0 270.3           |           ^~~~~~~~~
#0 270.3           |           atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:390:10: error: ??__int_as_float?? was not declared in this scope
#0 270.3       390 |   return __int_as_float(old);
#0 270.3           |          ^~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMaxIntegerImpl<T, 1>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMaxIntegerImpl<T, 2>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMaxIntegerImpl<T, 4>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:138:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       138 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:138:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       138 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMaxIntegerImpl<T, 8>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In lambda function:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:432:75: error: ??__longlong_as_double?? was not declared in this scope
#0 270.3       432 |                                 return __double_as_longlong(safe_max(val, __longlong_as_double(assumed)));
#0 270.3           |                                                                           ^~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:432:40: error: ??__double_as_longlong?? was not declared in this scope
#0 270.3       432 |                                 return __double_as_longlong(safe_max(val, __longlong_as_double(assumed)));
#0 270.3           |                                        ^~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In function ??float gpuAtomicMax(float*, float)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:445:50: error: ??__int_as_float?? was not declared in this scope
#0 270.3       445 |                     __float_as_int(safe_max(val, __int_as_float(assumed))));
#0 270.3           |                                                  ^~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:445:21: error: ??__float_as_int?? was not declared in this scope
#0 270.3       445 |                     __float_as_int(safe_max(val, __int_as_float(assumed))));
#0 270.3           |                     ^~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:444:11: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       444 |     old = atomicCAS(address_as_ull, assumed,
#0 270.3           |           ^~~~~~~~~
#0 270.3           |           atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:450:10: error: ??__int_as_float?? was not declared in this scope
#0 270.3       450 |   return __int_as_float(old);
#0 270.3           |          ^~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMinIntegerImpl<T, 1>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMinIntegerImpl<T, 2>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMinIntegerImpl<T, 4>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:138:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       138 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:138:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       138 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In member function ??void AtomicMinIntegerImpl<T, 8>::operator()(T*, T, const func_t&)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:13: error: there are no arguments to ??atomicCAS?? that depend on a template parameter, so a declaration of ??atomicCAS?? must be available [-fpermissive]
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:13: note: in definition of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In lambda function:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:492:75: error: ??__longlong_as_double?? was not declared in this scope
#0 270.3       492 |                                 return __double_as_longlong(safe_min(val, __longlong_as_double(assumed)));
#0 270.3           |                                                                           ^~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:492:40: error: ??__double_as_longlong?? was not declared in this scope
#0 270.3       492 |                                 return __double_as_longlong(safe_min(val, __longlong_as_double(assumed)));
#0 270.3           |                                        ^~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In function ??float gpuAtomicMin(float*, float)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:505:50: error: ??__int_as_float?? was not declared in this scope
#0 270.3       505 |                     __float_as_int(safe_min(val, __int_as_float(assumed))));
#0 270.3           |                                                  ^~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:505:21: error: ??__float_as_int?? was not declared in this scope
#0 270.3       505 |                     __float_as_int(safe_min(val, __int_as_float(assumed))));
#0 270.3           |                     ^~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:504:11: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       504 |     old = atomicCAS(address_as_ull, assumed,
#0 270.3           |           ^~~~~~~~~
#0 270.3           |           atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:510:10: error: ??__int_as_float?? was not declared in this scope
#0 270.3       510 |   return __int_as_float(old);
#0 270.3           |          ^~~~~~~~~~~~~~
#0 270.3     In file included from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:6:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh: In function ??void at::cuda::{anonymous}::kernelPointwiseApply1(at::cuda::detail::TensorInfo<scalar, IndexType>, IndexType, Op)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:278:33: error: ??blockIdx?? was not declared in this scope; did you mean ??block_diag???
#0 270.3       278 |   for (IndexType linearIndex = (blockIdx.x * blockDim.x + threadIdx.x) * step;
#0 270.3           |                                 ^~~~~~~~
#0 270.3           |                                 block_diag
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:278:46: error: ??blockDim?? was not declared in this scope
#0 270.3       278 |   for (IndexType linearIndex = (blockIdx.x * blockDim.x + threadIdx.x) * step;
#0 270.3           |                                              ^~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:278:59: error: ??threadIdx?? was not declared in this scope
#0 270.3       278 |   for (IndexType linearIndex = (blockIdx.x * blockDim.x + threadIdx.x) * step;
#0 270.3           |                                                           ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:280:23: error: ??gridDim?? was not declared in this scope
#0 270.3       280 |        linearIndex += gridDim.x * blockDim.x * step) {
#0 270.3           |                       ^~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:282:16: error: ??::min?? has not been declared
#0 270.3       282 |       a, op, ::min(step, static_cast<int>(totalElements - linearIndex)), linearIndex);
#0 270.3           |                ^~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:282:16: note: suggested alternatives:
#0 270.3     In file included from /usr/include/c++/9/algorithm:62,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/string_view.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/StringUtil.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/include/c++/9/bits/stl_algo.h:3456:5: note:   ??std::min??
#0 270.3      3456 |     min(initializer_list<_Tp> __l, _Compare __comp)
#0 270.3           |     ^~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Functions.h:871,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ExpandUtils.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/input_metadata.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/custom_function.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:5,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ops/min.h:68:19: note:   ??at::min??
#0 270.3        68 | inline at::Tensor min(const at::Tensor & self, const at::Tensor & other) {
#0 270.3           |                   ^~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/string_view.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/StringUtil.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/C++17.h:456:20: note:   ??c10::guts::min??
#0 270.3       456 | constexpr const T& min(const T& a, const T& b) {
#0 270.3           |                    ^~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/ir/ir.h:18,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/function_impl.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/method.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/object.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/samplers/serialize.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/samplers.h:8,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/datasets/chunk.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/datasets.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:143:11: note:   ??c10::prim::min??
#0 270.3       143 |   _(prim, min)                       \
#0 270.3           |           ^~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:348:35: note: in definition of macro ??DEFINE_SYMBOL??
#0 270.3       348 |   namespace ns { constexpr Symbol s(static_cast<unique_t>(_keys::ns##_##s)); }
#0 270.3           |                                   ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:349:1: note: in expansion of macro ??FORALL_NS_SYMBOLS??
#0 270.3       349 | FORALL_NS_SYMBOLS(DEFINE_SYMBOL)
#0 270.3           | ^~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/aten_interned_strings.h:987:9: note:   ??c10::aten::min??
#0 270.3       987 | _(aten, min) \
#0 270.3           |         ^~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:348:35: note: in definition of macro ??DEFINE_SYMBOL??
#0 270.3       348 |   namespace ns { constexpr Symbol s(static_cast<unique_t>(_keys::ns##_##s)); }
#0 270.3           |                                   ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:230:3: note: in expansion of macro ??FORALL_ATEN_BASE_SYMBOLS??
#0 270.3       230 |   FORALL_ATEN_BASE_SYMBOLS(_)        \
#0 270.3           |   ^~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:349:1: note: in expansion of macro ??FORALL_NS_SYMBOLS??
#0 270.3       349 | FORALL_NS_SYMBOLS(DEFINE_SYMBOL)
#0 270.3           | ^~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/aten_interned_strings.h:1807:9: note:   ??c10::attr::min??
#0 270.3      1807 | _(attr, min) \
#0 270.3           |         ^~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:348:35: note: in definition of macro ??DEFINE_SYMBOL??
#0 270.3       348 |   namespace ns { constexpr Symbol s(static_cast<unique_t>(_keys::ns##_##s)); }
#0 270.3           |                                   ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:296:3: note: in expansion of macro ??FORALL_ATTR_BASE_SYMBOLS??
#0 270.3       296 |   FORALL_ATTR_BASE_SYMBOLS(_)        \
#0 270.3           |   ^~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:349:1: note: in expansion of macro ??FORALL_NS_SYMBOLS??
#0 270.3       349 | FORALL_NS_SYMBOLS(DEFINE_SYMBOL)
#0 270.3           | ^~~~~~~~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/MethodOperators.h:259,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:40,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ops/min_ops.h:61:18: note:   ??at::_ops::min??
#0 270.3        61 | struct TORCH_API min {
#0 270.3           |                  ^~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/NativeFunctions.h:825,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/TensorIndexing.h:13,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:18,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ops/min_native.h:27:22: note:   ??at::native::min??
#0 270.3        27 | TORCH_API at::Tensor min(const at::Tensor & self, const at::Tensor & other);
#0 270.3           |                      ^~~
#0 270.3     In file included from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:6:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh: In function ??void at::cuda::{anonymous}::kernelPointwiseApply2(at::cuda::detail::TensorInfo<scalar1, IndexType>, at::cuda::detail::TensorInfo<scalar2, IndexType>, IndexType, Op)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:367:33: error: ??blockIdx?? was not declared in this scope; did you mean ??block_diag???
#0 270.3       367 |   for (IndexType linearIndex = (blockIdx.x * blockDim.x + threadIdx.x) * step;
#0 270.3           |                                 ^~~~~~~~
#0 270.3           |                                 block_diag
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:367:46: error: ??blockDim?? was not declared in this scope
#0 270.3       367 |   for (IndexType linearIndex = (blockIdx.x * blockDim.x + threadIdx.x) * step;
#0 270.3           |                                              ^~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:367:59: error: ??threadIdx?? was not declared in this scope
#0 270.3       367 |   for (IndexType linearIndex = (blockIdx.x * blockDim.x + threadIdx.x) * step;
#0 270.3           |                                                           ^~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:369:23: error: ??gridDim?? was not declared in this scope
#0 270.3       369 |        linearIndex += gridDim.x * blockDim.x * step) {
#0 270.3           |                       ^~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:371:19: error: ??::min?? has not been declared
#0 270.3       371 |       a, b, op, ::min(step, static_cast<int>(totalElements - linearIndex)),
#0 270.3           |                   ^~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:371:19: note: suggested alternatives:
#0 270.3     In file included from /usr/include/c++/9/algorithm:62,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/string_view.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/StringUtil.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/include/c++/9/bits/stl_algo.h:3456:5: note:   ??std::min??
#0 270.3      3456 |     min(initializer_list<_Tp> __l, _Compare __comp)
#0 270.3           |     ^~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Functions.h:871,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ExpandUtils.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/input_metadata.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/custom_function.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:5,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ops/min.h:68:19: note:   ??at::min??
#0 270.3        68 | inline at::Tensor min(const at::Tensor & self, const at::Tensor & other) {
#0 270.3           |                   ^~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/string_view.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/StringUtil.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/C++17.h:456:20: note:   ??c10::guts::min??
#0 270.3       456 | constexpr const T& min(const T& a, const T& b) {
#0 270.3           |                    ^~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/ir/ir.h:18,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/function_impl.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/method.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/object.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/jit/api/module.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/input-archive.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/serialize/archive.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/samplers/serialize.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/samplers.h:8,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/datasets/chunk.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/datasets.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:143:11: note:   ??c10::prim::min??
#0 270.3       143 |   _(prim, min)                       \
#0 270.3           |           ^~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:348:35: note: in definition of macro ??DEFINE_SYMBOL??
#0 270.3       348 |   namespace ns { constexpr Symbol s(static_cast<unique_t>(_keys::ns##_##s)); }
#0 270.3           |                                   ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:349:1: note: in expansion of macro ??FORALL_NS_SYMBOLS??
#0 270.3       349 | FORALL_NS_SYMBOLS(DEFINE_SYMBOL)
#0 270.3           | ^~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/aten_interned_strings.h:987:9: note:   ??c10::aten::min??
#0 270.3       987 | _(aten, min) \
#0 270.3           |         ^~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:348:35: note: in definition of macro ??DEFINE_SYMBOL??
#0 270.3       348 |   namespace ns { constexpr Symbol s(static_cast<unique_t>(_keys::ns##_##s)); }
#0 270.3           |                                   ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:230:3: note: in expansion of macro ??FORALL_ATEN_BASE_SYMBOLS??
#0 270.3       230 |   FORALL_ATEN_BASE_SYMBOLS(_)        \
#0 270.3           |   ^~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:349:1: note: in expansion of macro ??FORALL_NS_SYMBOLS??
#0 270.3       349 | FORALL_NS_SYMBOLS(DEFINE_SYMBOL)
#0 270.3           | ^~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/aten_interned_strings.h:1807:9: note:   ??c10::attr::min??
#0 270.3      1807 | _(attr, min) \
#0 270.3           |         ^~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:348:35: note: in definition of macro ??DEFINE_SYMBOL??
#0 270.3       348 |   namespace ns { constexpr Symbol s(static_cast<unique_t>(_keys::ns##_##s)); }
#0 270.3           |                                   ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:296:3: note: in expansion of macro ??FORALL_ATTR_BASE_SYMBOLS??
#0 270.3       296 |   FORALL_ATTR_BASE_SYMBOLS(_)        \
#0 270.3           |   ^~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/interned_strings.h:349:1: note: in expansion of macro ??FORALL_NS_SYMBOLS??
#0 270.3       349 | FORALL_NS_SYMBOLS(DEFINE_SYMBOL)
#0 270.3           | ^~~~~~~~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/MethodOperators.h:259,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:40,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ops/min_ops.h:61:18: note:   ??at::_ops::min??
#0 270.3        61 | struct TORCH_API min {
#0 270.3           |                  ^~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/NativeFunctions.h:825,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/TensorIndexing.h:13,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:18,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/ops/min_native.h:27:22: note:   ??at::native::min??
#0 270.3        27 | TORCH_API at::Tensor min(const at::Tensor & self, const at::Tensor & other);
#0 270.3           |                      ^~~
#0 270.3     In file included from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:6:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh: In function ??bool at::cuda::CUDA_tensor_apply2(at::TensorBase, at::TensorBase, Op, at::cuda::TensorArgType, at::cuda::TensorArgType)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:6: error: expected primary-expression before ??<?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |      ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:453:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       453 |       HANDLE_CASE(TYPE, A, 1);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:467:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       467 |       HANDLE_B_CASE(TYPE, 1, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:66: error: expected primary-expression before ??>?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |                                                                  ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:453:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       453 |       HANDLE_CASE(TYPE, A, 1);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:467:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       467 |       HANDLE_B_CASE(TYPE, 1, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:6: error: expected primary-expression before ??<?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |      ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:456:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       456 |       HANDLE_CASE(TYPE, A, 2);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:467:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       467 |       HANDLE_B_CASE(TYPE, 1, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:66: error: expected primary-expression before ??>?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |                                                                  ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:456:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       456 |       HANDLE_CASE(TYPE, A, 2);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:467:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       467 |       HANDLE_B_CASE(TYPE, 1, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:6: error: expected primary-expression before ??<?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |      ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:459:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       459 |       HANDLE_CASE(TYPE, A, -1);             \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:467:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       467 |       HANDLE_B_CASE(TYPE, 1, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:66: error: expected primary-expression before ??>?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |                                                                  ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:459:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       459 |       HANDLE_CASE(TYPE, A, -1);             \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:467:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       467 |       HANDLE_B_CASE(TYPE, 1, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:6: error: expected primary-expression before ??<?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |      ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:453:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       453 |       HANDLE_CASE(TYPE, A, 1);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:470:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       470 |       HANDLE_B_CASE(TYPE, 2, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:66: error: expected primary-expression before ??>?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |                                                                  ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:453:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       453 |       HANDLE_CASE(TYPE, A, 1);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:470:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       470 |       HANDLE_B_CASE(TYPE, 2, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:6: error: expected primary-expression before ??<?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |      ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:456:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       456 |       HANDLE_CASE(TYPE, A, 2);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:470:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       470 |       HANDLE_B_CASE(TYPE, 2, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:66: error: expected primary-expression before ??>?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |                                                                  ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:456:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       456 |       HANDLE_CASE(TYPE, A, 2);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:470:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       470 |       HANDLE_B_CASE(TYPE, 2, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:6: error: expected primary-expression before ??<?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |      ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:459:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       459 |       HANDLE_CASE(TYPE, A, -1);             \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:470:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       470 |       HANDLE_B_CASE(TYPE, 2, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:66: error: expected primary-expression before ??>?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |                                                                  ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:459:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       459 |       HANDLE_CASE(TYPE, A, -1);             \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:470:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       470 |       HANDLE_B_CASE(TYPE, 2, B);            \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:6: error: expected primary-expression before ??<?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |      ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:453:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       453 |       HANDLE_CASE(TYPE, A, 1);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:473:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       473 |       HANDLE_B_CASE(TYPE, -1, B);           \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:66: error: expected primary-expression before ??>?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |                                                                  ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:453:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       453 |       HANDLE_CASE(TYPE, A, 1);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:473:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       473 |       HANDLE_B_CASE(TYPE, -1, B);           \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:6: error: expected primary-expression before ??<?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |      ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:456:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       456 |       HANDLE_CASE(TYPE, A, 2);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:473:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       473 |       HANDLE_B_CASE(TYPE, -1, B);           \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:66: error: expected primary-expression before ??>?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |                                                                  ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:456:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       456 |       HANDLE_CASE(TYPE, A, 2);              \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:473:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       473 |       HANDLE_B_CASE(TYPE, -1, B);           \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:6: error: expected primary-expression before ??<?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |      ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:459:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       459 |       HANDLE_CASE(TYPE, A, -1);             \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:473:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       473 |       HANDLE_B_CASE(TYPE, -1, B);           \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:66: error: expected primary-expression before ??>?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |                                                                  ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:459:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       459 |       HANDLE_CASE(TYPE, A, -1);             \
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:473:7: note: in expansion of macro ??HANDLE_B_CASE??
#0 270.3       473 |       HANDLE_B_CASE(TYPE, -1, B);           \
#0 270.3           |       ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:489:5: note: in expansion of macro ??HANDLE_A_CASE??
#0 270.3       489 |     HANDLE_A_CASE(unsigned int, aInfo.dims, bInfo.dims);
#0 270.3           |     ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:6: error: expected primary-expression before ??<?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |      ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:505:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       505 |       HANDLE_CASE(uint64_t, 1, 1);
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:66: error: expected primary-expression before ??>?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |                                                                  ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:505:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       505 |       HANDLE_CASE(uint64_t, 1, 1);
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:6: error: expected primary-expression before ??<?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |      ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:507:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       507 |       HANDLE_CASE(uint64_t, -1, -1);
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:446:66: error: expected primary-expression before ??>?? token
#0 270.3       446 |    <<<grid, block, 0, at::cuda::getCurrentCUDAStream(curDevice)>>>(    \
#0 270.3           |                                                                  ^
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:507:7: note: in expansion of macro ??HANDLE_CASE??
#0 270.3       507 |       HANDLE_CASE(uint64_t, -1, -1);
#0 270.3           |       ^~~~~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/THC/THCDeviceUtils.cuh:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:9:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh: In function ??unsigned int ACTIVE_MASK()??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh:10:12: error: ??__activemask?? was not declared in this scope
#0 270.3        10 |     return __activemask();
#0 270.3           |            ^~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh: In function ??unsigned int WARP_BALLOT(int, unsigned int)??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh:26:12: error: ??__ballot_sync?? was not declared in this scope
#0 270.3        26 |     return __ballot_sync(mask, predicate);
#0 270.3           |            ^~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh: At global scope:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh:34:79: error: ??warpSize?? was not declared in this scope
#0 270.3        34 | __device__ __forceinline__ T WARP_SHFL_XOR(T value, int laneMask, int width = warpSize, unsigned int mask = 0xffffffff)
#0 270.3           |                                                                               ^~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh:44:74: error: ??warpSize?? was not declared in this scope
#0 270.3        44 | __device__ __forceinline__ T WARP_SHFL(T value, int srcLane, int width = warpSize, unsigned int mask = 0xffffffff)
#0 270.3           |                                                                          ^~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh:54:84: error: ??warpSize?? was not declared in this scope
#0 270.3        54 | __device__ __forceinline__ T WARP_SHFL_UP(T value, unsigned int delta, int width = warpSize, unsigned int mask = 0xffffffff)
#0 270.3           |                                                                                    ^~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh:64:86: error: ??warpSize?? was not declared in this scope
#0 270.3        64 | __device__ __forceinline__ T WARP_SHFL_DOWN(T value, unsigned int delta, int width = warpSize, unsigned int mask = 0xffffffff)
#0 270.3           |                                                                                      ^~~~~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/THC/THCDeviceUtils.cuh:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:9:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh:92:114: error: ??warpSize?? was not declared in this scope
#0 270.3        92 | __device__ __forceinline__ c10::complex<T> WARP_SHFL_DOWN(c10::complex<T> value, unsigned int delta, int width = warpSize, unsigned int mask = 0xffffffff)
#0 270.3           |                                                                                                                  ^~~~~~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp: In function ??at::Tensor BuildCostVolume_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, int)??:
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:26:17: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        26 |   if (left.type().is_cuda())
#0 270.3           |                 ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp: In function ??std::tuple<at::Tensor, at::Tensor> BuildCostVolume_backward(const at::Tensor&, const at::Tensor&, int)??:
#0 270.3     /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:41:17: warning: ??at::DeprecatedTypeProperties& at::Tensor::type() const?? is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
#0 270.3        41 |   if (grad.type().is_cuda())
#0 270.3           |                 ^
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
#0 270.3                      from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:1:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here
#0 270.3       216 |   DeprecatedTypeProperties & type() const {
#0 270.3           |                              ^~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/CUDAApplyUtils.cuh:7,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:6:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicAddIntegerImpl<T, 1>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicAdd(bool*, bool)::<lambda(bool, bool)>; T = bool]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:171:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:170:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       170 | ATOMIC_INTEGER_IMPL(Add)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicAddIntegerImpl<T, 1>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicAdd(uint8_t*, uint8_t)::<lambda(uint8_t, uint8_t)>; T = unsigned char]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:179:53:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:170:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       170 | ATOMIC_INTEGER_IMPL(Add)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicAddIntegerImpl<T, 1>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicAdd(int8_t*, int8_t)::<lambda(int8_t, int8_t)>; T = signed char]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:187:51:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:170:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       170 | ATOMIC_INTEGER_IMPL(Add)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicAddIntegerImpl<T, 2>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicAdd(int16_t*, int16_t)::<lambda(int16_t, int16_t)>; T = short int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:195:53:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:170:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       170 | ATOMIC_INTEGER_IMPL(Add)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicAddIntegerImpl<T, 8>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicAdd(int64_t*, int64_t)::<lambda(int64_t, int64_t)>; T = long int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:210:53:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:170:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       170 | ATOMIC_INTEGER_IMPL(Add)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMulIntegerImpl<T, 1>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMul(uint8_t*, uint8_t)::<lambda(uint8_t, uint8_t)>; T = unsigned char]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:348:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:347:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       347 | ATOMIC_INTEGER_IMPL(Mul)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMulIntegerImpl<T, 1>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMul(int8_t*, int8_t)::<lambda(int8_t, int8_t)>; T = signed char]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:349:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:347:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       347 | ATOMIC_INTEGER_IMPL(Mul)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMulIntegerImpl<T, 2>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMul(int16_t*, int16_t)::<lambda(int16_t, int16_t)>; T = short int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:350:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:347:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       347 | ATOMIC_INTEGER_IMPL(Mul)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMulIntegerImpl<T, 4>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMul(int32_t*, int32_t)::<lambda(int32_t, int32_t)>; T = int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:351:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:138:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       138 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:347:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       347 | ATOMIC_INTEGER_IMPL(Mul)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMulIntegerImpl<T, 8>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMul(int64_t*, int64_t)::<lambda(int64_t, int64_t)>; T = long int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:352:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:347:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       347 | ATOMIC_INTEGER_IMPL(Mul)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??c10::Half AtomicFPOp<c10::Half>::operator()(c10::Half*, c10::Half, const func_t&) [with func_t = gpuAtomicMul(c10::Half*, c10::Half)::<lambda(c10::Half, c10::Half)>]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:358:34:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:31:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        31 |       old = atomicCAS(address_as_ui, assumed, old);
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3           |             atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??c10::BFloat16 AtomicFPOp<c10::BFloat16>::operator()(c10::BFloat16*, c10::BFloat16, const func_t&) [with func_t = gpuAtomicMul(c10::BFloat16*, c10::BFloat16)::<lambda(c10::BFloat16, c10::BFloat16)>]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:365:38:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:53:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        53 |       old = atomicCAS(address_as_ui, assumed, old);
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3           |             atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??double AtomicFPOp<double>::operator()(double*, double, const func_t&) [with func_t = gpuAtomicMul(double*, double)::<lambda(double, long long unsigned int)>]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:372:32:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:70:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        70 |       old = atomicCAS(address_as_ull, assumed, func(val, assumed));
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3           |             atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:74:32: error: ??__longlong_as_double?? was not declared in this scope
#0 270.3        74 |     return __longlong_as_double(old);
#0 270.3           |            ~~~~~~~~~~~~~~~~~~~~^~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMaxIntegerImpl<T, 1>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMax(uint8_t*, uint8_t)::<lambda(uint8_t, uint8_t)>; T = unsigned char]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:409:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:408:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       408 | ATOMIC_INTEGER_IMPL(Max)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMaxIntegerImpl<T, 1>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMax(int8_t*, int8_t)::<lambda(int8_t, int8_t)>; T = signed char]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:410:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:408:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       408 | ATOMIC_INTEGER_IMPL(Max)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMaxIntegerImpl<T, 2>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMax(int16_t*, int16_t)::<lambda(int16_t, int16_t)>; T = short int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:411:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:408:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       408 | ATOMIC_INTEGER_IMPL(Max)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMaxIntegerImpl<T, 4>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMax(int32_t*, int32_t)::<lambda(int32_t, int32_t)>; T = int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:412:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:138:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       138 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:408:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       408 | ATOMIC_INTEGER_IMPL(Max)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMaxIntegerImpl<T, 8>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMax(int64_t*, int64_t)::<lambda(int64_t, int64_t)>; T = long int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:413:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:408:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       408 | ATOMIC_INTEGER_IMPL(Max)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??c10::Half AtomicFPOp<c10::Half>::operator()(c10::Half*, c10::Half, const func_t&) [with func_t = gpuAtomicMax(c10::Half*, c10::Half)::<lambda(c10::Half, c10::Half)>]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:419:34:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:31:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        31 |       old = atomicCAS(address_as_ui, assumed, old);
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3           |             atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??c10::BFloat16 AtomicFPOp<c10::BFloat16>::operator()(c10::BFloat16*, c10::BFloat16, const func_t&) [with func_t = gpuAtomicMax(c10::BFloat16*, c10::BFloat16)::<lambda(c10::BFloat16, c10::BFloat16)>]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:426:38:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:53:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        53 |       old = atomicCAS(address_as_ui, assumed, old);
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3           |             atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??double AtomicFPOp<double>::operator()(double*, double, const func_t&) [with func_t = gpuAtomicMax(double*, double)::<lambda(double, long long unsigned int)>]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:433:32:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:70:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        70 |       old = atomicCAS(address_as_ull, assumed, func(val, assumed));
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3           |             atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:74:32: error: ??__longlong_as_double?? was not declared in this scope
#0 270.3        74 |     return __longlong_as_double(old);
#0 270.3           |            ~~~~~~~~~~~~~~~~~~~~^~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMinIntegerImpl<T, 1>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMin(uint8_t*, uint8_t)::<lambda(uint8_t, uint8_t)>; T = unsigned char]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:469:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:468:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       468 | ATOMIC_INTEGER_IMPL(Min)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMinIntegerImpl<T, 1>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMin(int8_t*, int8_t)::<lambda(int8_t, int8_t)>; T = signed char]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:470:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:99:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        99 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:468:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       468 | ATOMIC_INTEGER_IMPL(Min)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMinIntegerImpl<T, 2>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMin(int16_t*, int16_t)::<lambda(int16_t, int16_t)>; T = short int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:471:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:121:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       121 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:468:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       468 | ATOMIC_INTEGER_IMPL(Min)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMinIntegerImpl<T, 4>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMin(int32_t*, int32_t)::<lambda(int32_t, int32_t)>; T = int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:472:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:138:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       138 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:468:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       468 | ATOMIC_INTEGER_IMPL(Min)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??void AtomicMinIntegerImpl<T, 8>::operator()(T*, T, const func_t&) [with func_t = gpuAtomicMin(int64_t*, int64_t)::<lambda(int64_t, int64_t)>; T = long int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:473:1:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:155:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3       155 |       old = atomicCAS(address_as_ui, assumed, newval);                                                                 \
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:468:1: note: in expansion of macro ??ATOMIC_INTEGER_IMPL??
#0 270.3       468 | ATOMIC_INTEGER_IMPL(Min)
#0 270.3           | ^~~~~~~~~~~~~~~~~~~
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??c10::Half AtomicFPOp<c10::Half>::operator()(c10::Half*, c10::Half, const func_t&) [with func_t = gpuAtomicMin(c10::Half*, c10::Half)::<lambda(c10::Half, c10::Half)>]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:479:34:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:31:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        31 |       old = atomicCAS(address_as_ui, assumed, old);
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3           |             atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??c10::BFloat16 AtomicFPOp<c10::BFloat16>::operator()(c10::BFloat16*, c10::BFloat16, const func_t&) [with func_t = gpuAtomicMin(c10::BFloat16*, c10::BFloat16)::<lambda(c10::BFloat16, c10::BFloat16)>]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:486:38:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:53:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        53 |       old = atomicCAS(address_as_ui, assumed, old);
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3           |             atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh: In instantiation of ??double AtomicFPOp<double>::operator()(double*, double, const func_t&) [with func_t = gpuAtomicMin(double*, double)::<lambda(double, long long unsigned int)>]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:493:32:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:70:22: error: ??atomicCAS?? was not declared in this scope; did you mean ??atomicAdd???
#0 270.3        70 |       old = atomicCAS(address_as_ull, assumed, func(val, assumed));
#0 270.3           |             ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3           |             atomicAdd
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/Atomic.cuh:74:32: error: ??__longlong_as_double?? was not declared in this scope
#0 270.3        74 |     return __longlong_as_double(old);
#0 270.3           |            ~~~~~~~~~~~~~~~~~~~~^~~~~
#0 270.3     In file included from /usr/local/lib/python3.8/dist-packages/torch/include/THC/THCDeviceUtils.cuh:3,
#0 270.3                      from /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume.cpp:9:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh: In instantiation of ??T WARP_SHFL_DOWN(T, unsigned int, int, unsigned int) [with T = short unsigned int]??:
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh:88:78:   required from here
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/cuda/DeviceUtils.cuh:67:28: error: ??__shfl_down_sync?? was not declared in this scope
#0 270.3        67 |     return __shfl_down_sync(mask, value, delta, width);
#0 270.3           |            ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~
#0 270.3     [2/2] /usr/local/cuda/bin/nvcc  -DWITH_CUDA -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c -c /home/dsgn2/DSGN2_fork/pcdet/ops/build_cost_volume/src/BuildCostVolume_cuda.cu -o /home/dsgn2/DSGN2_fork/build/temp.linux-aarch64-3.8/pcdet/ops/build_cost_volume/src/BuildCostVolume_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1013"' -DTORCH_EXTENSION_NAME=build_cost_volume_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -gencode=arch=compute_61,code=compute_61 -gencode=arch=compute_61,code=sm_61 -std=c++14
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/irange.h(54): warning: pointless comparison of unsigned integer with zero
#0 270.3               detected during:
#0 270.3                 instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]"
#0 270.3     (61): here
#0 270.3                 instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]"
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorImpl.h(77): here
#0 270.3     
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/irange.h(54): warning: pointless comparison of unsigned integer with zero
#0 270.3               detected during:
#0 270.3                 instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]"
#0 270.3     (61): here
#0 270.3                 instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]"
#0 270.3     /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/qualified_name.h(73): here
#0 270.3     
#0 270.3     ninja: build stopped: subcommand failed.
#0 270.3     Traceback (most recent call last):
#0 270.3       File "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py", line 1890, in _run_ninja_build
#0 270.3         subprocess.run(
#0 270.3       File "/usr/lib/python3.8/subprocess.py", line 516, in run
#0 270.3         raise CalledProcessError(retcode, process.args,
#0 270.3     subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.
#0 270.3     
#0 270.3     The above exception was the direct cause of the following exception:
#0 270.3     
#0 270.3     Traceback (most recent call last):
#0 270.3       File "<string>", line 1, in <module>
#0 270.3       File "/home/dsgn2/DSGN2_fork/setup.py", line 31, in <module>
#0 270.3         setup(
#0 270.3       File "/usr/lib/python3/dist-packages/setuptools/__init__.py", line 144, in setup
#0 270.3         return distutils.core.setup(**attrs)
#0 270.3       File "/usr/lib/python3.8/distutils/core.py", line 148, in setup
#0 270.3         dist.run_commands()
#0 270.3       File "/usr/lib/python3.8/distutils/dist.py", line 966, in run_commands
#0 270.3         self.run_command(cmd)
#0 270.3       File "/usr/lib/python3.8/distutils/dist.py", line 985, in run_command
#0 270.3         cmd_obj.run()
#0 270.3       File "/usr/lib/python3/dist-packages/setuptools/command/develop.py", line 38, in run
#0 270.3         self.install_for_development()
#0 270.3       File "/usr/lib/python3/dist-packages/setuptools/command/develop.py", line 140, in install_for_development
#0 270.3         self.run_command('build_ext')
#0 270.3       File "/usr/lib/python3.8/distutils/cmd.py", line 313, in run_command
#0 270.3         self.distribution.run_command(command)
#0 270.3       File "/usr/lib/python3.8/distutils/dist.py", line 985, in run_command
#0 270.3         cmd_obj.run()
#0 270.3       File "/usr/lib/python3/dist-packages/setuptools/command/build_ext.py", line 87, in run
#0 270.3         _build_ext.run(self)
#0 270.3       File "/home/dsgn2/.local/lib/python3.8/site-packages/Cython/Distutils/old_build_ext.py", line 186, in run
#0 270.3         _build_ext.build_ext.run(self)
#0 270.3       File "/usr/lib/python3.8/distutils/command/build_ext.py", line 340, in run
#0 270.3         self.build_extensions()
#0 270.3       File "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py", line 845, in build_extensions
#0 270.3         build_ext.build_extensions(self)
#0 270.3       File "/home/dsgn2/.local/lib/python3.8/site-packages/Cython/Distutils/old_build_ext.py", line 195, in build_extensions
#0 270.3         _build_ext.build_ext.build_extensions(self)
#0 270.3       File "/usr/lib/python3.8/distutils/command/build_ext.py", line 449, in build_extensions
#0 270.3         self._build_extensions_serial()
#0 270.3       File "/usr/lib/python3.8/distutils/command/build_ext.py", line 474, in _build_extensions_serial
#0 270.3         self.build_extension(ext)
#0 270.3       File "/usr/lib/python3/dist-packages/setuptools/command/build_ext.py", line 208, in build_extension
#0 270.3         _build_ext.build_extension(self, ext)
#0 270.3       File "/usr/lib/python3.8/distutils/command/build_ext.py", line 528, in build_extension
#0 270.3         objects = self.compiler.compile(sources,
#0 270.3       File "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py", line 660, in unix_wrap_ninja_compile
#0 270.3         _write_ninja_file_and_compile_objects(
#0 270.3       File "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py", line 1571, in _write_ninja_file_and_compile_objects
#0 270.3         _run_ninja_build(
#0 270.3       File "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py", line 1906, in _run_ninja_build
#0 270.3         raise RuntimeError(message) from e
#0 270.3     RuntimeError: Error compiling objects for extension
#0 270.3     ----------------------------------------
#0 270.3 ERROR: Command errored out with exit status 1: /usr/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '"'"'/home/dsgn2/DSGN2_fork/setup.py'"'"'; __file__='"'"'/home/dsgn2/DSGN2_fork/setup.py'"'"';f=getattr(tokenize, '"'"'open'"'"', open)(__file__);code=f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' develop --no-deps --user --prefix= Check the logs for full command output.
------
Dockerfile.aarch64:72
--------------------
  70 |     RUN python3 -c "import torch;print(torch.cuda.is_available());" \
  71 |      && pip3 install -U Cython
  72 | >>> RUN cd /home/${USER}/DSGN2_fork/ && pip3 install -r requirements.txt && pip3 install -e .
  73 |     # RUN cd /home/${USER}/DSGN2_fork/ && pip3 install -e .
  74 |     
--------------------
ERROR: failed to solve: process "/bin/bash -l -c cd /home/${USER}/DSGN2_fork/ && pip3 install -r requirements.txt && pip3 install -e ." did not complete successfully: exit code: 1
ERROR: Service 'jetson-app' failed to build : Build failed
